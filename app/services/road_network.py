import pandas as pd
import csv
import networkx as nx
from shapely.geometry import Point, LineString, box
from shapely.strtree import STRtree
from leuvenmapmatching.map.inmem import InMemMap
import logging
import os
import pickle

# ÈÖçÁΩÆË∑ØÂæÑ
DATA_DIR = "../data"
LOCAL_ROAD_FILE = os.path.join(DATA_DIR, "25M3_rbeijing_gcj02.csv")
CACHE_FILE = os.path.join(DATA_DIR, "road_network_cache.pkl")
CACHE_VERSION = 2


class RoadNetwork:
    def __init__(self):
        self.gdf = None
        self.sindex = None
        self.geometries = []
        self.indices = []
        self.is_loaded = False
        self.hmm_map = None
        self.graph = None
        self.edge_geom_map = {}
        self.sindex_ready = False
        self.graph_ready = False
        self.hmm_index_ready = False

    @staticmethod
    def _parse_linestring_wkt(wkt: str):
        wkt = str(wkt).strip().strip('"')
        if not wkt.upper().startswith("LINESTRING"):
            return []
        start = wkt.find("(")
        end = wkt.rfind(")")
        if start == -1 or end == -1:
            return []
        coords_part = wkt[start + 1: end]
        coords = []
        for pair in coords_part.split(","):
            parts = pair.strip().split()
            if len(parts) < 2:
                continue
            lon = float(parts[0])
            lat = float(parts[1])
            coords.append((lat, lon))
        return coords

    @staticmethod
    def _read_header(path: str):
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            header_parts = []
            for line in f:
                if line.lstrip().startswith('"LINESTRING') or line.lstrip().startswith("LINESTRING"):
                    break
                header_parts.append(line.rstrip("\n"))
            header_line = "".join(part.strip() for part in header_parts)
            return next(csv.reader([header_line]))

    @staticmethod
    def _read_header_and_first_data_line(path: str):
        f = open(path, "r", encoding="utf-8", errors="ignore")
        header_parts = []
        first_data_line = ""
        for line in f:
            if line.lstrip().startswith('"LINESTRING') or line.lstrip().startswith("LINESTRING"):
                first_data_line = line.rstrip("\n")
                break
            header_parts.append(line.rstrip("\n"))
        header_line = "".join(part.strip() for part in header_parts)
        header = next(csv.reader([header_line]))
        return header, first_data_line, f

    def _iter_rows(self, path: str):
        header, first_data_line, f = self._read_header_and_first_data_line(path)
        ncols = len(header)

        def parse_line(line: str):
            return next(csv.reader([line], skipinitialspace=True))

        buffer = first_data_line
        for line in f:
            if not buffer:
                buffer = line.rstrip("\n")
                continue
            row = parse_line(buffer)
            if len(row) < ncols:
                buffer += line.rstrip("\n")
                continue
            yield row
            buffer = line.rstrip("\n")

        if buffer:
            try:
                row = parse_line(buffer)
                if len(row) == ncols:
                    yield row
            finally:
                f.close()
        else:
            f.close()

    def _ensure_hmm_index(self):
        """‰∏∫ leuvenmapmatching ÁöÑ InMemMap ÊûÑÂª∫Á©∫Èó¥Á¥¢ÂºïÔºàÂ¶ÇÂèØÁî®Ôºâ„ÄÇ"""
        if self.hmm_map is None:
            return
        try:
            if hasattr(self.hmm_map, "build_spatial_index"):
                self.hmm_map.build_spatial_index()
                logging.info("‚úÖ HMM Á©∫Èó¥Á¥¢ÂºïÂ∑≤ÊûÑÂª∫")
                self.hmm_index_ready = True
                return
            if hasattr(self.hmm_map, "index"):
                idx = self.hmm_map.index
                if callable(idx):
                    idx()
                    logging.info("‚úÖ HMM Á¥¢ÂºïÂ∑≤ÊûÑÂª∫ (index())")
                    self.hmm_index_ready = True
                else:
                    logging.info("‚úÖ HMM Á¥¢ÂºïÂ∑≤Â≠òÂú®")
                    self.hmm_index_ready = True
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è HMM Á¥¢ÂºïÊûÑÂª∫Â§±Ë¥•: {e}")
            self.hmm_index_ready = False

    def _ensure_sindex(self):
        """ÊåâÈúÄÊûÑÂª∫Á©∫Èó¥Á¥¢ÂºïÔºàSTRtreeÔºâ„ÄÇ"""
        if self.sindex_ready and self.sindex is not None:
            return
        if self.gdf is None or self.gdf.empty:
            return
        if not self.geometries:
            self.geometries = list(self.gdf['shapely_geom'])
            self.indices = list(self.gdf.index)
        logging.info("‚ö° Ê≠£Âú®ÊûÑÂª∫Á©∫Èó¥Á¥¢Âºï...")
        self.sindex = STRtree(self.geometries)
        self.sindex_ready = True

    def _ensure_graph(self):
        """ÊåâÈúÄÊûÑÂª∫Ë∑ØÁΩëÊãìÊâëÂõæ„ÄÇ"""
        if self.graph_ready and self.graph is not None:
            return
        self._build_graph_and_edge_map()
        self.graph_ready = self.graph is not None

    def ensure_sindex(self):
        self._ensure_sindex()

    def ensure_graph(self):
        self._ensure_graph()

    def ensure_hmm_index(self):
        if not self.hmm_index_ready:
            self._ensure_hmm_index()

    def _normalize_node_id(self, node_id):
        """Áªü‰∏ÄËäÇÁÇπID‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÈÅøÂÖç 123 ‰∏é 123.0 ‰∏çÂåπÈÖç„ÄÇ"""
        s = str(node_id)
        if s.endswith('.0'):
            s = s[:-2]
        return s

    def normalize_node_id(self, node_id):
        """ÂØπÂ§ñÊö¥Èú≤ÁöÑËäÇÁÇπIDÂΩí‰∏ÄÂåñÊñπÊ≥ï„ÄÇ"""
        return self._normalize_node_id(node_id)

    def has_node(self, node_id):
        """Âà§Êñ≠ËäÇÁÇπÊòØÂê¶Â≠òÂú®‰∫éÊãìÊâëÂõæ‰∏≠„ÄÇ"""
        if self.graph is None:
            return False
        key = self._normalize_node_id(node_id)
        return key in self.graph

    def load_local_file(self, lazy: bool | None = None):
        """
        Êô∫ËÉΩÂä†ËΩΩÔºö‰ºòÂÖàËØªÂèñ .pkl ÁºìÂ≠òÔºåÂ¶ÇÊûúÊ≤°ÊúâÂàôËß£Êûê CSV Âπ∂ÁîüÊàêÁºìÂ≠ò
        """
        if lazy is None:
            lazy = str(os.environ.get("ROAD_NETWORK_LAZY", "1")).lower() in ("1", "true", "yes")
        if os.path.exists(CACHE_FILE):
            try:
                logging.info(f"üöÄ ÂèëÁé∞ÁºìÂ≠òÊñá‰ª∂ÔºåÊ≠£Âú®Âø´ÈÄüÊÅ¢Â§çË∑ØÁΩë: {CACHE_FILE}")
                with open(CACHE_FILE, 'rb') as f:
                    cache_data = pickle.load(f)

                if cache_data.get('cache_version') != CACHE_VERSION:
                    raise ValueError("cache_version_mismatch")

                self.gdf = cache_data['gdf']
                self.hmm_map = cache_data['hmm_map']
                self.geometries = list(self.gdf['shapely_geom'])
                self.indices = list(self.gdf.index)
                if 'SnodeID' in self.gdf.columns and 'EnodeID' in self.gdf.columns:
                    self.gdf['SnodeID'] = self.gdf['SnodeID'].astype(str).map(self._normalize_node_id)
                    self.gdf['EnodeID'] = self.gdf['EnodeID'].astype(str).map(self._normalize_node_id)
                self.is_loaded = True

                if not lazy:
                    logging.info("‚ö° Ê≠£Âú®ÈáçÂª∫Á©∫Èó¥Á¥¢Âºï...")
                    self.sindex = STRtree(self.geometries)
                    self.sindex_ready = True
                    self._build_graph_and_edge_map()
                    self.graph_ready = self.graph is not None
                    self._ensure_hmm_index()
                else:
                    self.sindex = None
                    self.graph = None
                    self.edge_geom_map = {}
                    self.sindex_ready = False
                    self.graph_ready = False
                    self.hmm_index_ready = False
                    logging.info("‚ö° Â∑≤ÂêØÁî®ÊáíÂä†ËΩΩÔºåÁ¥¢Âºï/ÂõæÂ∞ÜÂú®È¶ñÊ¨°‰ΩøÁî®Êó∂ÊûÑÂª∫")

                logging.info(f"‚úÖ ÁºìÂ≠òÂä†ËΩΩÊàêÂäü! (HMMËäÇÁÇπÊï∞: {self.hmm_map.size()})")
                return True, "ÁºìÂ≠òÂä†ËΩΩÊàêÂäü"
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è ÁºìÂ≠òÊñá‰ª∂ÊçüÂùèÊàñÁâàÊú¨‰∏çÂÖºÂÆπÔºåÂ∞ÜÈáçÊñ∞Ëß£Êûê CSV: {e}")

        if not os.path.exists(LOCAL_ROAD_FILE):
            logging.error(f"Ë∑ØÁΩëÊñá‰ª∂Êú™ÊâæÂà∞: {LOCAL_ROAD_FILE}")
            return False, "Êñá‰ª∂‰∏çÂ≠òÂú®"

        try:
            logging.info("üê¢ Êú™ÊâæÂà∞ÁºìÂ≠òÔºåÊ≠£Âú®‰ªé CSV Ëß£ÊûêË∑ØÁΩë (ËÄóÊó∂Êìç‰Ωú)...")

            header = self._read_header(LOCAL_ROAD_FILE)
            geom_idx = header.index("geometry") if "geometry" in header else None
            records = []
            valid_geoms = []
            valid_indices = []

            self.hmm_map = InMemMap("beijing_net", use_latlon=True)
            coord_index = {}

            for idx, row in enumerate(self._iter_rows(LOCAL_ROAD_FILE)):
                record = {header[i]: row[i] if i < len(row) else "" for i in range(len(header))}
                records.append(record)

                try:
                    geom_str = record.get("geometry", "") if geom_idx is not None else ""
                    coords = self._parse_linestring_wkt(geom_str)
                    if not coords:
                        continue

                    geom = LineString([(lon, lat) for lat, lon in coords])
                    valid_geoms.append(geom)
                    valid_indices.append(idx)

                    direction = record.get('Direction', 1)
                    try:
                        direction = int(float(direction))
                    except Exception:
                        direction = 1

                    prev_node_id = None
                    for lat, lon in coords:
                        key = (round(lat, 6), round(lon, 6))
                        node_id = coord_index.get(key)
                        if node_id is None:
                            node_id = f"n{len(coord_index)}"
                            coord_index[key] = node_id
                            self.hmm_map.add_node(node_id, (lat, lon))

                        if prev_node_id is not None:
                            if direction == 1:
                                self.hmm_map.add_edge(prev_node_id, node_id)
                                self.hmm_map.add_edge(node_id, prev_node_id)
                            elif direction == 2:
                                self.hmm_map.add_edge(prev_node_id, node_id)
                            elif direction == 3:
                                self.hmm_map.add_edge(node_id, prev_node_id)
                            else:
                                self.hmm_map.add_edge(prev_node_id, node_id)
                                self.hmm_map.add_edge(node_id, prev_node_id)

                        prev_node_id = node_id
                except Exception:
                    continue

            df = pd.DataFrame.from_records(records)

            df['shapely_geom'] = [None] * len(df)
            for i, list_idx in enumerate(valid_indices):
                df.at[list_idx, 'shapely_geom'] = valid_geoms[i]

            self.gdf = df.dropna(subset=['shapely_geom'])
            if 'SnodeID' in self.gdf.columns and 'EnodeID' in self.gdf.columns:
                self.gdf['SnodeID'] = self.gdf['SnodeID'].astype(str).map(self._normalize_node_id)
                self.gdf['EnodeID'] = self.gdf['EnodeID'].astype(str).map(self._normalize_node_id)
            self.geometries = valid_geoms
            self.indices = valid_indices
            self.is_loaded = True
            if not lazy:
                self.sindex = STRtree(self.geometries)
                self.sindex_ready = True
                self._build_graph_and_edge_map()
                self.graph_ready = self.graph is not None
                self._ensure_hmm_index()
            else:
                self.sindex = None
                self.graph = None
                self.edge_geom_map = {}
                self.sindex_ready = False
                self.graph_ready = False
                self.hmm_index_ready = False

            logging.info(f"üíæ Ê≠£Âú®ÁîüÊàêÁºìÂ≠òÊñá‰ª∂ (‰∏ãÊ¨°ÂêØÂä®Â∞ÜÁßíÂºÄ)...")
            try:
                cache_data = {
                    'cache_version': CACHE_VERSION,
                    'gdf': self.gdf,
                    'hmm_map': self.hmm_map,
                }
                with open(CACHE_FILE, 'wb') as f:
                    pickle.dump(cache_data, f)
                logging.info(f"‚úÖ ÁºìÂ≠ò‰øùÂ≠òÂÆåÊØï: {CACHE_FILE}")
            except Exception as e:
                logging.error(f"‚ùå ÁºìÂ≠ò‰øùÂ≠òÂ§±Ë¥•: {e}")

            return True, "Âä†ËΩΩÊàêÂäü (Â∑≤ÁîüÊàêÁºìÂ≠ò)"

        except Exception as e:
            logging.error(f"Âä†ËΩΩÂºÇÂ∏∏: {e}")
            import traceback
            traceback.print_exc()
            return False, str(e)

    def _build_graph_and_edge_map(self):
        """Âü∫‰∫é gdf ÊûÑÂª∫ÊúâÂêëÂõæÂíåËæπ->Âá†‰ΩïÊò†Â∞ÑÔºå‰æø‰∫éË∑ØÂæÑË°•ÂÖ®„ÄÇ"""
        if self.gdf is None or self.gdf.empty:
            self.graph = None
            self.edge_geom_map = {}
            return

        self.graph = nx.DiGraph()
        self.edge_geom_map = {}

        def _line_length_m(line):
            coords = list(line.coords)
            if len(coords) < 2:
                return 0.0
            total = 0.0
            for i in range(len(coords) - 1):
                lon1, lat1 = coords[i]
                lon2, lat2 = coords[i + 1]
                dx = (lon2 - lon1) * 111000 * 0.76
                dy = (lat2 - lat1) * 111000
                total += (dx * dx + dy * dy) ** 0.5
            return total

        for _, row in self.gdf.iterrows():
            geom = row.get('shapely_geom', None)
            if geom is None:
                continue
            s_node = self._normalize_node_id(row.get('SnodeID', ''))
            e_node = self._normalize_node_id(row.get('EnodeID', ''))
            if not s_node or not e_node:
                continue

            length_m = _line_length_m(geom)
            direction = row.get('Direction', 1)
            try:
                direction = int(float(direction))
            except Exception:
                direction = 1

            def _add_edge(u, v):
                self.graph.add_edge(u, v, length=length_m)
                key = (u, v)
                if key not in self.edge_geom_map:
                    self.edge_geom_map[key] = []
                self.edge_geom_map[key].append((length_m, geom))

            if direction == 1:
                _add_edge(s_node, e_node)
                _add_edge(e_node, s_node)
            elif direction == 2:
                _add_edge(s_node, e_node)
            elif direction == 3:
                _add_edge(e_node, s_node)
            else:
                _add_edge(s_node, e_node)
                _add_edge(e_node, s_node)
        self.graph_ready = True

    def get_shortest_path_edges(self, u, v):
        """ËøîÂõûÊúÄÁü≠Ë∑ØÂæÑÁöÑËæπÂ∫èÂàó [(n1,n2), ...]ÔºåÂ§±Ë¥•ÂàôÁ©∫ÂàóË°®„ÄÇ"""
        try:
            if self.graph is None:
                self._ensure_graph()
                if self.graph is None:
                    return []
            u_key = self._normalize_node_id(u)
            v_key = self._normalize_node_id(v)
            if u_key not in self.graph or v_key not in self.graph:
                return []
            path_nodes = nx.shortest_path(self.graph, source=u_key, target=v_key, weight='length')
            if not path_nodes or len(path_nodes) < 2:
                return []
            return list(zip(path_nodes[:-1], path_nodes[1:]))
        except Exception:
            return []

    def get_candidates(self, lat, lon, radius=50):
        if not self.is_loaded:
            return []
        self._ensure_sindex()
        if self.sindex is None:
            return []
        buffer_deg = radius / 111000.0
        query_box = box(lon - buffer_deg, lat - buffer_deg, lon + buffer_deg, lat + buffer_deg)
        candidate_indices = self.sindex.query(query_box)
        candidates = []
        point = Point(lon, lat)
        for idx in candidate_indices:
            geom = self.geometries[idx]
            dist_deg = point.distance(geom)
            dist_m = dist_deg * 111000
            if dist_m <= radius:
                row_idx = self.indices[idx]
                row = self.gdf.loc[row_idx]
                proj_dist = geom.project(point)
                proj_point = geom.interpolate(proj_dist)
                candidates.append({
                    "edge_id": row.get('ID', idx),
                    "dist_m": dist_m,
                    "proj_point": proj_point,
                    "geometry": geom,
                })
        return candidates

    def query_roads_in_bounds(self, min_lat, min_lon, max_lat, max_lon, buffer=0.01):
        if not self.is_loaded:
            return []
        self._ensure_sindex()
        if self.sindex is None:
            return []
        search_box = box(min_lon - buffer, min_lat - buffer, max_lon + buffer, max_lat + buffer)
        indices = self.sindex.query(search_box)
        segments = []
        for idx in indices:
            geom = self.geometries[idx]
            line = [[p[1], p[0]] for p in geom.coords]
            segments.append(line)
        return segments

    def get_edge_geometry(self, u, v):
        try:
            self._ensure_graph()
            u_key = self._normalize_node_id(u)
            v_key = self._normalize_node_id(v)
            key = (u_key, v_key)
            if key in self.edge_geom_map and self.edge_geom_map[key]:
                return sorted(self.edge_geom_map[key], key=lambda x: x[0])[0][1]
            rows = self.gdf[(self.gdf['SnodeID'] == u_key) & (self.gdf['EnodeID'] == v_key)]
            if not rows.empty:
                return rows.iloc[0]['shapely_geom']

            rows = self.gdf[(self.gdf['SnodeID'] == v_key) & (self.gdf['EnodeID'] == u_key)]
            if not rows.empty:
                return rows.iloc[0]['shapely_geom']
            return None
        except Exception:
            return None


road_network_service = RoadNetwork()
