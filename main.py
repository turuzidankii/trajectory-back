from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import pandas as pd
import io
import math
from road_network import road_network_service
from algorithms import TrajectoryProcessor

@asynccontextmanager
async def lifespan(app: FastAPI):
    print(">>> ç³»ç»Ÿå¯åŠ¨...")
    # å¯åŠ¨æ—¶åŠ è½½è·¯ç½‘
    success, msg = road_network_service.load_local_file()
    print(f">>> è·¯ç½‘åŠ è½½çŠ¶æ€: {msg}")
    yield

app = FastAPI(lifespan=lifespan)

# å…è®¸è·¨åŸŸ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/road_network/status")
async def get_road_status():
    # ğŸ”¥ ä¿®å¤ç‚¹ï¼šç§»é™¤äº†å¯¹ .graph çš„å¼•ç”¨
    count = 0
    if road_network_service.is_loaded and road_network_service.gdf is not None:
        count = len(road_network_service.gdf)
        
    return {
        "loaded": road_network_service.is_loaded,
        "nodes": count
    }

@app.get("/road_network/nearby")
async def get_nearby_roads(min_lat: float, min_lon: float, max_lat: float, max_lon: float):
    """
    è·å–å¯è§†åŒºåŸŸå†…çš„è·¯ç½‘ä¾›å‰ç«¯ç»˜åˆ¶
    """
    if not road_network_service.is_loaded:
        return {"status": "error", "data": []}
    
    # è°ƒç”¨ road_network ä¸­çš„ç©ºé—´æŸ¥è¯¢
    segments = road_network_service.query_roads_in_bounds(min_lat, min_lon, max_lat, max_lon)
    return {"status": "success", "data": segments}

@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    content = await file.read()
    try:
        # 1. å°è¯•è¯»å– CSV
        # ä¼˜å…ˆå°è¯•è¯»å–æ— è¡¨å¤´æ ¼å¼ (å› ä¸ºæ‚¨çš„æ–‡ä»¶çœ‹èµ·æ¥æ²¡æœ‰æ ‡å‡†è‹±æ–‡è¡¨å¤´)
        try:
            # å‡è®¾å‰5åˆ—æ˜¯: road_name, status, distance, duration, polyline
            df = pd.read_csv(io.BytesIO(content), header=None, 
                             names=['road', 'status', 'distance', 'duration', 'polyline'])
        except:
            # å¦‚æœå¤±è´¥ï¼Œå°è¯•è‡ªåŠ¨æ¨æ–­
            df = pd.read_csv(io.BytesIO(content))
        
        df = df.fillna("")
        points = []

        # 2. è§£æé€»è¾‘ (é’ˆå¯¹ "lon-lat|lon-lat" æ ¼å¼)
        # æ‚¨çš„æ•°æ®æ ¼å¼ç¤ºä¾‹: "116.573884-39.78614|116.574103-39.786246"
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®åˆ—
        if 'polyline' in df.columns:
            for idx, row in df.iterrows():
                polyline_str = str(row['polyline'])
                if not polyline_str or polyline_str.lower() == 'nan':
                    continue

                # ä»…å–ç¬¬ä¸€ä¸ªç‚¹ï¼Œä¿æŒåŸé€»è¾‘
                first_point_str = polyline_str.split('|')[0] if '|' in polyline_str else polyline_str

                # è§£æ "lon-lat" (æ³¨æ„æ‚¨çš„æ•°æ®æ˜¯ç”¨å‡å·åˆ†éš”ç»çº¬åº¦çš„)
                if '-' in first_point_str:
                    try:
                        parts = first_point_str.split('-')
                        if len(parts) >= 2:
                            lon = float(parts[0])
                            lat = float(parts[1])

                            # ç®€å•çš„æœ‰æ•ˆæ€§æ£€æŸ¥
                            if not (0 <= lon <= 180 and 0 <= lat <= 90):
                                continue

                            points.append({
                                'id': idx,
                                'lat': lat,
                                'lon': lon,
                                # ä¼ªé€ ä¸€ä¸ªæ—¶é—´æˆ³ï¼Œä¿è¯é¡ºåº (å› ä¸ºHMMéœ€è¦)
                                # å‡è®¾æ•°æ®æ˜¯æŒ‰æ—¶é—´é¡ºåºè®°å½•çš„ï¼Œæ¯è¡Œé—´éš” 5 ç§’
                                'timestamp': pd.Timestamp('2024-01-01 08:00:00') + pd.Timedelta(seconds=idx * 5),
                                'road': str(row.get('road', '')),
                                'status': str(row.get('status', ''))
                            })
                    except ValueError:
                        continue
                        
        # 3. å…¼å®¹æ ‡å‡† GPS æ ¼å¼ (å¦‚æœæœ‰ lat, lon åˆ—)
        elif 'lat' in df.columns and 'lon' in df.columns:
            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                df = df.sort_values('timestamp')
            
            for idx, row in df.iterrows():
                points.append({
                    'id': idx,
                    'lat': row['lat'],
                    'lon': row['lon'],
                    'timestamp': row['timestamp'] if 'timestamp' in row else pd.Timestamp('2024-01-01') + pd.Timedelta(seconds=idx)
                })

        # 4. è¿”å›ç»“æœ
        print(f">>> è§£æå®Œæˆï¼Œæå–äº† {len(points)} ä¸ªç‚¹")
        return {
            "status": "success", 
            "count": len(points), 
            "data": points # å‰ç«¯ä¼šæ”¶åˆ°è¿™ä¸ªæ•°ç»„
        }
        
    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        return {"status": "error", "message": str(e)}

@app.post("/process")
async def process(data: dict):
    # æ¥æ”¶å‰ç«¯æ•°æ®
    raw_df = pd.DataFrame(data['trajectory'])
    config = data['config']
    
    processor = TrajectoryProcessor(raw_df)
    
    # 1. é¢„å¤„ç†
    df_cleaned = processor.preprocess_pipeline(config)
    
    # 2. åŒ¹é…
    df_matched, msg = processor.map_match(df_cleaned, config.get('match_algo', 'HMM'), config)
    
    # 3. è´¨æ£€
    report = processor.quality_check(df_cleaned)
    
    return {
        "trajectory_processed": df_cleaned.to_dict(orient='records'),
        "trajectory_matched": df_matched.to_dict(orient='records'),
        "quality_report": report,
        "message": msg
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)