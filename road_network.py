import pandas as pd
import csv
import networkx as nx
from shapely.geometry import Point, LineString, box
from shapely.strtree import STRtree
from leuvenmapmatching.map.inmem import InMemMap
import logging
import os
import pickle  # ğŸ‘ˆ å¼•å…¥ pickle

# é…ç½®è·¯å¾„
DATA_DIR = "../data"
LOCAL_ROAD_FILE = os.path.join(DATA_DIR, "25M3_rbeijing_gcj02.csv") # ç¡®ä¿è¿™ä¸ªæ–‡ä»¶åå¯¹
# ğŸ”¥ ç¼“å­˜æ–‡ä»¶è·¯å¾„ (è‡ªåŠ¨ç”Ÿæˆ)
CACHE_FILE = os.path.join(DATA_DIR, "road_network_cache.pkl")
CACHE_VERSION = 2

class RoadNetwork:
    def __init__(self):
        self.gdf = None
        self.sindex = None
        self.geometries = []
        self.indices = []
        self.is_loaded = False
        self.hmm_map = None 
        self.graph = None
        self.edge_geom_map = {}

    @staticmethod
    def _parse_linestring_wkt(wkt: str):
        wkt = str(wkt).strip().strip('"')
        if not wkt.upper().startswith("LINESTRING"):
            return []
        start = wkt.find("(")
        end = wkt.rfind(")")
        if start == -1 or end == -1:
            return []
        coords_part = wkt[start + 1: end]
        coords = []
        for pair in coords_part.split(","):
            parts = pair.strip().split()
            if len(parts) < 2:
                continue
            lon = float(parts[0])
            lat = float(parts[1])
            coords.append((lat, lon))
        return coords

    @staticmethod
    def _read_header(path: str):
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            header_parts = []
            for line in f:
                if line.lstrip().startswith('"LINESTRING') or line.lstrip().startswith("LINESTRING"):
                    break
                header_parts.append(line.rstrip("\n"))
            header_line = "".join(part.strip() for part in header_parts)
            return next(csv.reader([header_line]))

    @staticmethod
    def _read_header_and_first_data_line(path: str):
        f = open(path, "r", encoding="utf-8", errors="ignore")
        header_parts = []
        first_data_line = ""
        for line in f:
            if line.lstrip().startswith('"LINESTRING') or line.lstrip().startswith("LINESTRING"):
                first_data_line = line.rstrip("\n")
                break
            header_parts.append(line.rstrip("\n"))
        header_line = "".join(part.strip() for part in header_parts)
        header = next(csv.reader([header_line]))
        return header, first_data_line, f

    def _iter_rows(self, path: str):
        header, first_data_line, f = self._read_header_and_first_data_line(path)
        ncols = len(header)

        def parse_line(line: str):
            return next(csv.reader([line], skipinitialspace=True))

        buffer = first_data_line
        for line in f:
            if not buffer:
                buffer = line.rstrip("\n")
                continue
            row = parse_line(buffer)
            if len(row) < ncols:
                buffer += line.rstrip("\n")
                continue
            yield row
            buffer = line.rstrip("\n")

        if buffer:
            try:
                row = parse_line(buffer)
                if len(row) == ncols:
                    yield row
            finally:
                f.close()
        else:
            f.close()

    def _ensure_hmm_index(self):
        """ä¸º leuvenmapmatching çš„ InMemMap æ„å»ºç©ºé—´ç´¢å¼•ï¼ˆå¦‚å¯ç”¨ï¼‰ã€‚"""
        if self.hmm_map is None:
            return
        try:
            if hasattr(self.hmm_map, "build_spatial_index"):
                self.hmm_map.build_spatial_index()
                logging.info("âœ… HMM ç©ºé—´ç´¢å¼•å·²æ„å»º")
                return
            if hasattr(self.hmm_map, "index"):
                # æŸäº›ç‰ˆæœ¬å¯èƒ½æä¾› index å±æ€§æˆ–æ–¹æ³•
                idx = self.hmm_map.index
                if callable(idx):
                    idx()
                    logging.info("âœ… HMM ç´¢å¼•å·²æ„å»º (index())")
                else:
                    logging.info("âœ… HMM ç´¢å¼•å·²å­˜åœ¨")
        except Exception as e:
            logging.warning(f"âš ï¸ HMM ç´¢å¼•æ„å»ºå¤±è´¥: {e}")

    def _normalize_node_id(self, node_id):
        """ç»Ÿä¸€èŠ‚ç‚¹IDä¸ºå­—ç¬¦ä¸²ï¼Œé¿å… 123 ä¸ 123.0 ä¸åŒ¹é…ã€‚"""
        s = str(node_id)
        if s.endswith('.0'):
            s = s[:-2]
        return s

    def normalize_node_id(self, node_id):
        """å¯¹å¤–æš´éœ²çš„èŠ‚ç‚¹IDå½’ä¸€åŒ–æ–¹æ³•ã€‚"""
        return self._normalize_node_id(node_id)

    def has_node(self, node_id):
        """åˆ¤æ–­èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨äºæ‹“æ‰‘å›¾ä¸­ã€‚"""
        if self.graph is None:
            return False
        key = self._normalize_node_id(node_id)
        return key in self.graph

    def load_local_file(self):
        """
        æ™ºèƒ½åŠ è½½ï¼šä¼˜å…ˆè¯»å– .pkl ç¼“å­˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™è§£æ CSV å¹¶ç”Ÿæˆç¼“å­˜
        """
        # 1. å°è¯•è¯»å–ç¼“å­˜ (æé€Ÿæ¨¡å¼)
        if os.path.exists(CACHE_FILE):
            try:
                logging.info(f"ğŸš€ å‘ç°ç¼“å­˜æ–‡ä»¶ï¼Œæ­£åœ¨å¿«é€Ÿæ¢å¤è·¯ç½‘: {CACHE_FILE}")
                with open(CACHE_FILE, 'rb') as f:
                    cache_data = pickle.load(f)

                if cache_data.get('cache_version') != CACHE_VERSION:
                    raise ValueError("cache_version_mismatch")
                
                # æ¢å¤æ•°æ®
                self.gdf = cache_data['gdf']
                self.hmm_map = cache_data['hmm_map']
                self.geometries = list(self.gdf['shapely_geom']) # ç¡®ä¿è½¬å› list
                self.indices = list(self.gdf.index)
                # ç»Ÿä¸€èŠ‚ç‚¹IDç±»å‹ï¼Œé¿å…åŒ¹é…å‡ ä½•å¤±è´¥
                if 'SnodeID' in self.gdf.columns and 'EnodeID' in self.gdf.columns:
                    self.gdf['SnodeID'] = self.gdf['SnodeID'].astype(str).map(self._normalize_node_id)
                    self.gdf['EnodeID'] = self.gdf['EnodeID'].astype(str).map(self._normalize_node_id)
                
                # âš ï¸ STRtree é€šå¸¸ä¸èƒ½ç›´æ¥ pickle (åŒ…å« C æŒ‡é’ˆ)ï¼Œéœ€è¦é‡æ–°æ„å»º
                # ä½†æ„å»ºæ ‘æ¯”è§£æ CSV å¿«å¾—å¤šï¼Œç¬é—´å°±èƒ½å®Œæˆ
                logging.info("âš¡ æ­£åœ¨é‡å»ºç©ºé—´ç´¢å¼•...")
                self.sindex = STRtree(self.geometries)
                
                self.is_loaded = True
                # é‡å»ºæ‹“æ‰‘å›¾ä¸è¾¹å‡ ä½•ç´¢å¼•
                self._build_graph_and_edge_map()
                # é‡æ–°æ„å»º HMM ç©ºé—´ç´¢å¼•
                self._ensure_hmm_index()
                logging.info(f"âœ… ç¼“å­˜åŠ è½½æˆåŠŸ! (HMMèŠ‚ç‚¹æ•°: {self.hmm_map.size()})")
                return True, "ç¼“å­˜åŠ è½½æˆåŠŸ"
            except Exception as e:
                logging.warning(f"âš ï¸ ç¼“å­˜æ–‡ä»¶æŸåæˆ–ç‰ˆæœ¬ä¸å…¼å®¹ï¼Œå°†é‡æ–°è§£æ CSV: {e}")
                # å¦‚æœè¯»å–ç¼“å­˜å¤±è´¥ï¼Œå°±ç»§ç»­å¾€ä¸‹èµ°ï¼Œé‡æ–°è§£æ CSV

        # 2. è§£æ CSV (æ…¢é€Ÿæ¨¡å¼ - ä»…ç¬¬ä¸€æ¬¡)
        if not os.path.exists(LOCAL_ROAD_FILE):
            logging.error(f"è·¯ç½‘æ–‡ä»¶æœªæ‰¾åˆ°: {LOCAL_ROAD_FILE}")
            return False, "æ–‡ä»¶ä¸å­˜åœ¨"
        
        try:
            logging.info("ğŸ¢ æœªæ‰¾åˆ°ç¼“å­˜ï¼Œæ­£åœ¨ä» CSV è§£æè·¯ç½‘ (è€—æ—¶æ“ä½œ)...")
            
            # --- è§£æé€»è¾‘ï¼šæ¨¡ä»¿ match_and_plot çš„ CSV è¯»å–æ–¹å¼ ---
            header = self._read_header(LOCAL_ROAD_FILE)
            geom_idx = header.index("geometry") if "geometry" in header else None
            records = []
            valid_geoms = []
            valid_indices = []

            self.hmm_map = InMemMap("beijing_net", use_latlon=True)
            coord_index = {}

            for idx, row in enumerate(self._iter_rows(LOCAL_ROAD_FILE)):
                record = {header[i]: row[i] if i < len(row) else "" for i in range(len(header))}
                records.append(record)

                try:
                    geom_str = record.get("geometry", "") if geom_idx is not None else ""
                    coords = self._parse_linestring_wkt(geom_str)
                    if not coords:
                        continue

                    geom = LineString([(lon, lat) for lat, lon in coords])
                    valid_geoms.append(geom)
                    valid_indices.append(idx)

                    direction = record.get('Direction', 1)
                    try:
                        direction = int(float(direction))
                    except Exception:
                        direction = 1

                    prev_node_id = None
                    for lat, lon in coords:
                        key = (round(lat, 6), round(lon, 6))
                        node_id = coord_index.get(key)
                        if node_id is None:
                            node_id = f"n{len(coord_index)}"
                            coord_index[key] = node_id
                            self.hmm_map.add_node(node_id, (lat, lon))

                        if prev_node_id is not None:
                            if direction == 1:
                                self.hmm_map.add_edge(prev_node_id, node_id)
                                self.hmm_map.add_edge(node_id, prev_node_id)
                            elif direction == 2:
                                self.hmm_map.add_edge(prev_node_id, node_id)
                            elif direction == 3:
                                self.hmm_map.add_edge(node_id, prev_node_id)
                            else:
                                self.hmm_map.add_edge(prev_node_id, node_id)
                                self.hmm_map.add_edge(node_id, prev_node_id)

                        prev_node_id = node_id
                except Exception:
                    continue

            df = pd.DataFrame.from_records(records)

            # ä¿å­˜åˆ° self
            df['shapely_geom'] = [None] * len(df)
            for i, list_idx in enumerate(valid_indices):
                df.at[list_idx, 'shapely_geom'] = valid_geoms[i]

            self.gdf = df.dropna(subset=['shapely_geom'])
            # ç»Ÿä¸€èŠ‚ç‚¹IDç±»å‹ï¼Œé¿å…åŒ¹é…å‡ ä½•å¤±è´¥
            if 'SnodeID' in self.gdf.columns and 'EnodeID' in self.gdf.columns:
                self.gdf['SnodeID'] = self.gdf['SnodeID'].astype(str).map(self._normalize_node_id)
                self.gdf['EnodeID'] = self.gdf['EnodeID'].astype(str).map(self._normalize_node_id)
            self.geometries = valid_geoms
            self.indices = valid_indices
            self.sindex = STRtree(self.geometries)
            self.is_loaded = True
            # æ„å»ºæ‹“æ‰‘å›¾ä¸è¾¹å‡ ä½•ç´¢å¼•
            self._build_graph_and_edge_map()
            # æ„å»º HMM ç©ºé—´ç´¢å¼•
            self._ensure_hmm_index()
            
            # 3. ğŸ”¥ ç”Ÿæˆç¼“å­˜æ–‡ä»¶ ğŸ”¥
            logging.info(f"ğŸ’¾ æ­£åœ¨ç”Ÿæˆç¼“å­˜æ–‡ä»¶ (ä¸‹æ¬¡å¯åŠ¨å°†ç§’å¼€)...")
            try:
                cache_data = {
                    'cache_version': CACHE_VERSION,
                    'gdf': self.gdf,
                    'hmm_map': self.hmm_map
                }
                with open(CACHE_FILE, 'wb') as f:
                    pickle.dump(cache_data, f)
                logging.info(f"âœ… ç¼“å­˜ä¿å­˜å®Œæ¯•: {CACHE_FILE}")
            except Exception as e:
                logging.error(f"âŒ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

            return True, f"åŠ è½½æˆåŠŸ (å·²ç”Ÿæˆç¼“å­˜)"
            
        except Exception as e:
            logging.error(f"åŠ è½½å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False, str(e)

    def _build_graph_and_edge_map(self):
        """åŸºäº gdf æ„å»ºæœ‰å‘å›¾å’Œè¾¹->å‡ ä½•æ˜ å°„ï¼Œä¾¿äºè·¯å¾„è¡¥å…¨ã€‚"""
        if self.gdf is None or self.gdf.empty:
            self.graph = None
            self.edge_geom_map = {}
            return

        self.graph = nx.DiGraph()
        self.edge_geom_map = {}

        def _line_length_m(line):
            # åŸºäºç»çº¬åº¦çš„è¿‘ä¼¼é•¿åº¦ (ç±³)
            coords = list(line.coords)
            if len(coords) < 2:
                return 0.0
            total = 0.0
            for i in range(len(coords) - 1):
                lon1, lat1 = coords[i]
                lon2, lat2 = coords[i + 1]
                # ç®€å•è¿‘ä¼¼ï¼šç»çº¬åº¦è½¬ç±³
                dx = (lon2 - lon1) * 111000 * 0.76
                dy = (lat2 - lat1) * 111000
                total += (dx * dx + dy * dy) ** 0.5
            return total

        for _, row in self.gdf.iterrows():
            geom = row.get('shapely_geom', None)
            if geom is None:
                continue
            s_node = self._normalize_node_id(row.get('SnodeID', ''))
            e_node = self._normalize_node_id(row.get('EnodeID', ''))
            if not s_node or not e_node:
                continue

            length_m = _line_length_m(geom)
            direction = row.get('Direction', 1)
            try:
                direction = int(float(direction))
            except Exception:
                direction = 1

            def _add_edge(u, v):
                self.graph.add_edge(u, v, length=length_m)
                key = (u, v)
                if key not in self.edge_geom_map:
                    self.edge_geom_map[key] = []
                self.edge_geom_map[key].append((length_m, geom))

            if direction == 1:
                _add_edge(s_node, e_node)
                _add_edge(e_node, s_node)
            elif direction == 2:
                _add_edge(s_node, e_node)
            elif direction == 3:
                _add_edge(e_node, s_node)
            else:
                _add_edge(s_node, e_node)
                _add_edge(e_node, s_node)

    def get_shortest_path_edges(self, u, v):
        """è¿”å›æœ€çŸ­è·¯å¾„çš„è¾¹åºåˆ— [(n1,n2), ...]ï¼Œå¤±è´¥åˆ™ç©ºåˆ—è¡¨ã€‚"""
        try:
            if self.graph is None:
                return []
            u_key = self._normalize_node_id(u)
            v_key = self._normalize_node_id(v)
            if u_key not in self.graph or v_key not in self.graph:
                return []
            path_nodes = nx.shortest_path(self.graph, source=u_key, target=v_key, weight='length')
            if not path_nodes or len(path_nodes) < 2:
                return []
            return list(zip(path_nodes[:-1], path_nodes[1:]))
        except Exception:
            return []

    def get_candidates(self, lat, lon, radius=50):
        if not self.is_loaded: return []
        buffer_deg = radius / 111000.0
        query_box = box(lon - buffer_deg, lat - buffer_deg, lon + buffer_deg, lat + buffer_deg)
        candidate_indices = self.sindex.query(query_box)
        candidates = []
        point = Point(lon, lat)
        for idx in candidate_indices:
            geom = self.geometries[idx]
            dist_deg = point.distance(geom)
            dist_m = dist_deg * 111000 
            if dist_m <= radius:
                row_idx = self.indices[idx] 
                row = self.gdf.loc[row_idx]
                proj_dist = geom.project(point) 
                proj_point = geom.interpolate(proj_dist)
                candidates.append({
                    "edge_id": row.get('ID', idx),
                    "dist_m": dist_m,
                    "proj_point": proj_point,
                    "geometry": geom # ä¾›æ‰‹å†™HMMä½¿ç”¨
                })
        return candidates

    def query_roads_in_bounds(self, min_lat, min_lon, max_lat, max_lon, buffer=0.01):
        if not self.is_loaded: return []
        search_box = box(min_lon - buffer, min_lat - buffer, max_lon + buffer, max_lat + buffer)
        indices = self.sindex.query(search_box)
        segments = []
        for idx in indices:
            geom = self.geometries[idx]
            line = [[p[1], p[0]] for p in geom.coords]
            segments.append(line)
        return segments

    def get_edge_geometry(self, u, v):
        try:
            u_key = self._normalize_node_id(u)
            v_key = self._normalize_node_id(v)
            # å…ˆä»è¾¹æ˜ å°„ä¸­å–å‡ ä½•
            key = (u_key, v_key)
            if key in self.edge_geom_map and self.edge_geom_map[key]:
                # é€‰æ‹©æœ€çŸ­çš„ä¸€æ¡ä½œä¸ºä»£è¡¨
                return sorted(self.edge_geom_map[key], key=lambda x: x[0])[0][1]
            rows = self.gdf[(self.gdf['SnodeID'] == u_key) & (self.gdf['EnodeID'] == v_key)]
            if not rows.empty: return rows.iloc[0]['shapely_geom']
            
            rows = self.gdf[(self.gdf['SnodeID'] == v_key) & (self.gdf['EnodeID'] == u_key)]
            if not rows.empty: return rows.iloc[0]['shapely_geom']
            return None
        except:
            return None

road_network_service = RoadNetwork()